{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "import random\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.python.keras.layers.recurrent_v2 import LSTM\r\n",
    "\r\n",
    "import data_generator\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# generate the data\r\n",
    "\r\n",
    "x_set = [];\r\n",
    "y_set = [];\r\n",
    "\r\n",
    "for i in range(0,10):\r\n",
    "    graphset = data_generator.get_graphset(i);\r\n",
    "    x_set.append(graphset[0]);\r\n",
    "    y_set.append(graphset[1]);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# split the data into training and testing sets\r\n",
    "\r\n",
    "half = int(len(x_set)/2);\r\n",
    "\r\n",
    "print(f'half: {half}')\r\n",
    "x_train = x_set[0:half]\r\n",
    "x_test = x_set[half:]\r\n",
    "\r\n",
    "y_train = x_set[0:half]\r\n",
    "y_test = x_set[half:]\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "half: 5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# print some data diagnostics to ensure we correctly obtained data sets\r\n",
    "\r\n",
    "print(\"number of x data points:\");\r\n",
    "print(len(x_train[1]));\r\n",
    "\r\n",
    "\r\n",
    "print(\"number of y data points:\");\r\n",
    "print(len(y_train[1]));\r\n",
    "\r\n",
    "assert(len(x_train) == len(y_train));\r\n",
    "print(f\"\\nNumber of training graph-solution sets: {len(x_train)}\")\r\n",
    "\r\n",
    "assert(len(x_test) == len(y_test));\r\n",
    "print(f\"Number of testing graph-solution sets: {len(x_test)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of x data points:\n",
      "5000\n",
      "number of y data points:\n",
      "5000\n",
      "\n",
      "Number of training graph-solution sets: 5\n",
      "Number of testing graph-solution sets: 5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#build the model by stacking layers; choose optimizer and loss function. Here we set the activation function to a 'relu'\r\n",
    "model = tf.keras.models.Sequential([\r\n",
    "  tf.keras.layers.LSTM(28),\r\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\r\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\r\n",
    "  tf.keras.layers.Dropout(0.2),\r\n",
    "  tf.keras.layers.Dense(10)\r\n",
    "])\r\n",
    "\r\n",
    "print(\"model built\");"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model built\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# get the predictions for the second datapoint\r\n",
    "predictions = model(x_train[0])\r\n",
    "\r\n",
    "# print the raw predictions fort that datapoint. Note that these are \"logits\" or \"log-odds\" scores, which is related to the probability, \r\n",
    "# and also is the inverse of the sigmoid function\r\n",
    "print(\"logits prediction: \");\r\n",
    "print(predictions);\r\n",
    "\r\n",
    "# we can use the softmax function to convert these logits to probabilities for each preciction class\r\n",
    "print(\"odds prediction: \");\r\n",
    "print(tf.nn.softmax(predictions).numpy());\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Layer sequential_1 expects 1 input(s), but it received 5 input tensors. Inputs received: [<tf.Tensor: shape=(5000,), dtype=float64, numpy=\narray([ 284191.94963941,  284663.94190978,  285134.17099082, ...,\n       2728518.14283222, 2728639.50959567, 2728760.8612571 ])>, <tf.Tensor: shape=(5000,), dtype=float64, numpy=\narray([0.96409574, 0.96406287, 0.96403002, ..., 0.80598931, 0.80596096,\n       0.80593261])>, <tf.Tensor: shape=(5000,), dtype=float64, numpy=\narray([1.00010647, 1.00010666, 1.00010684, ..., 1.00314408, 1.0031451 ,\n       1.00314612])>, <tf.Tensor: shape=(5000,), dtype=float64, numpy=\narray([0.99999969, 0.99999969, 0.99999969, ..., 0.99995431, 0.99995429,\n       0.99995427])>, <tf.Tensor: shape=(5000,), dtype=float64, numpy=\narray([1.        , 1.        , 1.        , ..., 1.00000066, 1.00000067,\n       1.00000067])>]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6624/1242068773.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# get the predictions for the second datapoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print the raw predictions fort that datapoint. Note that these are \"logits\" or \"log-odds\" scores, which is related to the probability,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# and also is the inverse of the sigmoid function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         training=training_mode):\n\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     raise ValueError('Layer ' + layer_name + ' expects ' +\n\u001b[0m\u001b[0;32m    201\u001b[0m                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' input(s), '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                      \u001b[1;34m'but it received '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer sequential_1 expects 1 input(s), but it received 5 input tensors. Inputs received: [<tf.Tensor: shape=(5000,), dtype=float64, numpy=\narray([ 284191.94963941,  284663.94190978,  285134.17099082, ...,\n       2728518.14283222, 2728639.50959567, 2728760.8612571 ])>, <tf.Tensor: shape=(5000,), dtype=float64, numpy=\narray([0.96409574, 0.96406287, 0.96403002, ..., 0.80598931, 0.80596096,\n       0.80593261])>, <tf.Tensor: shape=(5000,), dtype=float64, numpy=\narray([1.00010647, 1.00010666, 1.00010684, ..., 1.00314408, 1.0031451 ,\n       1.00314612])>, <tf.Tensor: shape=(5000,), dtype=float64, numpy=\narray([0.99999969, 0.99999969, 0.99999969, ..., 0.99995431, 0.99995429,\n       0.99995427])>, <tf.Tensor: shape=(5000,), dtype=float64, numpy=\narray([1.        , 1.        , 1.        , ..., 1.00000066, 1.00000067,\n       1.00000067])>]"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "c10ae7e12ea03818c78a6003d4d50ef0e5e51e430c65513fe14b678a9b488bb3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}