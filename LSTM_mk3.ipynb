{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "import random\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "import data_generator\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "# generate the data\r\n",
    "\r\n",
    "x_set = [];\r\n",
    "y_set = [];\r\n",
    "\r\n",
    "for i in range(0,20):\r\n",
    "    graphset = data_generator.get_graphset(i);\r\n",
    "    x_set.append(graphset[0]);\r\n",
    "    y_set.append(graphset[1][0]);\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "# split the data into training and testing sets\r\n",
    "\r\n",
    "\r\n",
    "x_set = np.array(x_set);\r\n",
    "y_set = np.array(y_set);\r\n",
    "\r\n",
    "half = int(len(x_set)/2);\r\n",
    "\r\n",
    "print(f'half: {half}');\r\n",
    "x_train = x_set[0:half];\r\n",
    "x_test = x_set[half:];\r\n",
    "\r\n",
    "y_train = y_set[0:half];\r\n",
    "y_test = y_set[half:];\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "half: 10\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "# print some data diagnostics to ensure we correctly obtained data sets\r\n",
    "\r\n",
    "print(f\"x_set shape: {x_set.shape}\");\r\n",
    "print(f\"y_set shape: {y_set.shape}\");\r\n",
    "\r\n",
    "print(\"number of x data points:\");\r\n",
    "print(len(x_train[0:]));\r\n",
    "\r\n",
    "\r\n",
    "print(\"number of y data points:\");\r\n",
    "print(len(y_train[0:]));\r\n",
    "\r\n",
    "assert(len(x_train) == len(y_train));\r\n",
    "assert(len(x_test) == len(y_test));\r\n",
    "assert(x_set.shape == y_set.shape);\r\n",
    "\r\n",
    "print(f\"\\nNumber of training graph-solution sets: {len(x_train)}\")\r\n",
    "\r\n",
    "\r\n",
    "print(f\"Number of testing graph-solution sets: {len(x_test)}\")\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(f\"\\nDataset shape: {x_set.shape}\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_set shape: (20, 5000)\n",
      "y_set shape: (20, 5000)\n",
      "number of x data points:\n",
      "10\n",
      "number of y data points:\n",
      "10\n",
      "\n",
      "Number of training graph-solution sets: 10\n",
      "Number of testing graph-solution sets: 10\n",
      "\n",
      "Dataset shape: (20, 5000)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "#build the model by stacking layers; choose optimizer and loss function. Here we set the activation function to a 'relu'\r\n",
    "\r\n",
    "\r\n",
    "model = tf.keras.models.Sequential()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#return_sequences: whether the next layer is another RNN\r\n",
    "#model.add(LSTM(128,input_shape=( x_train.shape[1:] ), activation='relu',return_sequences=True)); \r\n",
    "\r\n",
    "model.add(Dense(5000,activation='relu'));\r\n",
    "model.add(Dropout(0.2));\r\n",
    "model.add(Dense(5000,activation='relu'));\r\n",
    "model.add(Dropout(0.2));\r\n",
    "model.add(Dense(5000,activation='relu'));\r\n",
    "model.add(Dropout(0.2));\r\n",
    "model.add(Dense(5000,activation='relu'));\r\n",
    "model.add(Dropout(0.2));\r\n",
    "model.add(Dense(5000,activation='softmax'));\r\n",
    "\r\n",
    "\r\n",
    "print(\"model built\");"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model built\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "# get the predictions for the second datapoint\r\n",
    "predictions = model(x_train[1:])\r\n",
    "\r\n",
    "# print the raw predictions for that datapoint. Note that these are \"logits\" or \"log-odds\" scores, which is related to the probability, \r\n",
    "# and also is the inverse of the sigmoid function\r\n",
    "print(\"logits prediction: \");\r\n",
    "print(predictions);\r\n",
    "\r\n",
    "# we can use the softmax function to convert these logits to probabilities for each preciction class\r\n",
    "print(\"odds prediction: \");\r\n",
    "print(tf.nn.softmax(predictions).numpy());\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "logits prediction: \n",
      "tf.Tensor(\n",
      "[[0.00025317 0.00017885 0.00014997 ... 0.00013215 0.00014596 0.0002594 ]\n",
      " [0.00026008 0.00017721 0.00014699 ... 0.00012164 0.00013868 0.00026708]\n",
      " [0.00026001 0.00017725 0.00014701 ... 0.00012178 0.00013875 0.000267  ]\n",
      " ...\n",
      " [0.00026001 0.00017725 0.00014701 ... 0.00012178 0.00013875 0.000267  ]\n",
      " [0.00026001 0.00017725 0.00014701 ... 0.00012178 0.00013875 0.000267  ]\n",
      " [0.00026001 0.00017725 0.00014701 ... 0.00012178 0.00013875 0.000267  ]], shape=(9, 5000), dtype=float32)\n",
      "odds prediction: \n",
      "[[0.00020001 0.0002     0.00019999 ... 0.00019999 0.00019999 0.00020001]\n",
      " [0.00020001 0.0002     0.00019999 ... 0.00019998 0.00019999 0.00020001]\n",
      " [0.00020001 0.0002     0.00019999 ... 0.00019998 0.00019999 0.00020001]\n",
      " ...\n",
      " [0.00020001 0.0002     0.00019999 ... 0.00019998 0.00019999 0.00020001]\n",
      " [0.00020001 0.0002     0.00019999 ... 0.00019998 0.00019999 0.00020001]\n",
      " [0.00020001 0.0002     0.00019999 ... 0.00019998 0.00019999 0.00020001]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "# get the loss function as a SparseCategoricalCrossentropy loss from tf.keras.losses. \r\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False);\r\n",
    "\r\n",
    "print(\"loss:\");\r\n",
    "print(loss_fn(y_train[1:], predictions).numpy());"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Shape mismatch: The shape of labels (received (45000,)) should equal the shape of logits except for the last dimension (received (9, 5000)).",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17840/1347426067.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\losses.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[0;32m    157\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\losses.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\losses.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[1;34m(y_true, y_pred, from_logits, axis)\u001b[0m\n\u001b[0;32m   1710\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m   \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1712\u001b[1;33m   return backend.sparse_categorical_crossentropy(\n\u001b[0m\u001b[0;32m   1713\u001b[0m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[0;32m   1714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m   4980\u001b[0m           labels=target, logits=output)\n\u001b[0;32m   4981\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4982\u001b[1;33m     res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n\u001b[0m\u001b[0;32m   4983\u001b[0m         labels=target, logits=output)\n\u001b[0;32m   4984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits_v2\u001b[1;34m(labels, logits, name)\u001b[0m\n\u001b[0;32m   4226\u001b[0m       \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mequal\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrank\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0mminus\u001b[0m \u001b[0mone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4227\u001b[0m   \"\"\"\n\u001b[1;32m-> 4228\u001b[1;33m   return sparse_softmax_cross_entropy_with_logits(\n\u001b[0m\u001b[0;32m   4229\u001b[0m       labels=labels, logits=logits, name=name)\n\u001b[0;32m   4230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m   4131\u001b[0m     if (static_shapes_fully_defined and\n\u001b[0;32m   4132\u001b[0m         labels_static_shape != logits.get_shape()[:-1]):\n\u001b[1;32m-> 4133\u001b[1;33m       raise ValueError(\"Shape mismatch: The shape of labels (received %s) \"\n\u001b[0m\u001b[0;32m   4134\u001b[0m                        \u001b[1;34m\"should equal the shape of logits except for the last \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4135\u001b[0m                        \"dimension (received %s).\" % (labels_static_shape,\n",
      "\u001b[1;31mValueError\u001b[0m: Shape mismatch: The shape of labels (received (45000,)) should equal the shape of logits except for the last dimension (received (9, 5000))."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3,decay=1e-5);\r\n",
    "\r\n",
    "model.compile(loss=loss_fn,optimizer=opt,metrics=['accuracy']);\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit(x_train,y_train,epochs=20,validation_data=(x_test,y_test));"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 4s 4s/step - loss: -1691929620250624.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 1s 748ms/step - loss: -32759983309324288.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 1s 759ms/step - loss: -237330581287862272.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 1s 753ms/step - loss: -957727060753645568.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 1s 788ms/step - loss: -2365119055456632832.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 1s 795ms/step - loss: -6067680206649294848.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 1s 758ms/step - loss: -10758435404764938240.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 1s 801ms/step - loss: -19100087077073584128.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 1s 801ms/step - loss: -36878978991978971136.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 1s 770ms/step - loss: -57580007775652544512.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 1s 807ms/step - loss: -84626771162012057600.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 1s 724ms/step - loss: -119598831953567023104.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 1s 711ms/step - loss: -198104903358726799360.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 1s 831ms/step - loss: -295895010136287084544.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 1s 727ms/step - loss: -374182771308728680448.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 1s 693ms/step - loss: -578456233966441594880.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 1s 702ms/step - loss: -662032241448206729216.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 1s 714ms/step - loss: -953235837778913132544.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 1s 730ms/step - loss: -1133601976999101857792.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 1s 750ms/step - loss: -1651275765622830530560.0000 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}