{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "import random\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, ELU\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from matplotlib import pyplot\r\n",
    "\r\n",
    "\r\n",
    "import sys\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(f'Using python version: {sys.version}\\n');\r\n",
    "print(f'Using TensorFlow version: {tf.version.VERSION}');\r\n",
    "print(f'Using numpy version: {np.version.version}');\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using python version: 3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]\n",
      "\n",
      "Using TensorFlow version: 2.5.0\n",
      "Using numpy version: 1.19.5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# load in the data \r\n",
    "\r\n",
    "full_dataset = np.load(\"ml_dataset.npy\");"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# split up the data into the x and y halves\r\n",
    "\r\n",
    "x_set = full_dataset[0];\r\n",
    "y_set = full_dataset[1];"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# split the data into training and testing sets\r\n",
    "\r\n",
    "\r\n",
    "half = int(len(x_set)/2);\r\n",
    "\r\n",
    "print(f'half: {half}');\r\n",
    "x_train = x_set[0:half];\r\n",
    "x_test = x_set[half:];\r\n",
    "\r\n",
    "y_train = y_set[0:half];\r\n",
    "y_test = y_set[half:];\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "half: 151\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# print some data diagnostics to ensure we correctly obtained data sets\r\n",
    "\r\n",
    "print(f\"x_set shape: {x_set.shape}\");\r\n",
    "print(f\"y_set shape: {y_set.shape}\");\r\n",
    "\r\n",
    "\r\n",
    "training_point_number = x_set.shape[1];\r\n",
    "print(f\"number of points in each graph set: {training_point_number}\");\r\n",
    "\r\n",
    "\r\n",
    "print(\"number of x training data sets:\");\r\n",
    "print(len(x_train[0:]));\r\n",
    "\r\n",
    "\r\n",
    "print(\"number of y training data sets:\");\r\n",
    "print(len(y_train[0:]));\r\n",
    "\r\n",
    "assert(len(x_train) == len(y_train));\r\n",
    "assert(len(x_test) == len(y_test));\r\n",
    "assert(x_set.shape == y_set.shape);\r\n",
    "\r\n",
    "print(f\"\\nNumber of training graph-solution sets: {len(x_train)}\")\r\n",
    "\r\n",
    "\r\n",
    "print(f\"Number of testing graph-solution sets: {len(x_test)}\")\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(f\"\\nDataset shape: {x_set.shape}\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_set shape: (302, 500)\n",
      "y_set shape: (302, 500)\n",
      "number of points in each graph set: 500\n",
      "number of x training data sets:\n",
      "151\n",
      "number of y training data sets:\n",
      "151\n",
      "\n",
      "Number of training graph-solution sets: 151\n",
      "Number of testing graph-solution sets: 151\n",
      "\n",
      "Dataset shape: (302, 500)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# reshape the x data into a column of 1 element rows for the LSTM\r\n",
    "\r\n",
    "\r\n",
    "x_train = x_train.reshape(x_train.shape[0],training_point_number,1);\r\n",
    "x_test = x_test.reshape(x_test.shape[0],training_point_number,1);\r\n",
    "\r\n",
    "print(x_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(151, 500, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "#build the model by stacking layers\r\n",
    "\r\n",
    "\r\n",
    "model = tf.keras.models.Sequential()\r\n",
    "\r\n",
    "model.add(LSTM(training_point_number));\r\n",
    "\r\n",
    "\r\n",
    "model.add(Dense(training_point_number,activation='tanh'));\r\n",
    "\r\n",
    "\r\n",
    "model.add(Dense(training_point_number,activation='exponential'));\r\n",
    "\r\n",
    "\r\n",
    "print(\"model built\");\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model built\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#print(y_train[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# get the predictions for the second datapoint\r\n",
    "predictions = model(x_train)\r\n",
    "\r\n",
    "# print the raw predictions for that datapoint. Note that these are \"logits\" or \"log-odds\" scores, which is related to the probability, \r\n",
    "# and also is the inverse of the sigmoid function\r\n",
    "print(\"logits prediction: \");\r\n",
    "print(predictions[0]);\r\n",
    "\r\n",
    "# we can use the softmax function to convert these logits to probabilities for each preciction class\r\n",
    "#print(\"odds prediction: \");\r\n",
    "#print(tf.nn.softmax(predictions).numpy()[0]);\r\n",
    "\r\n",
    "\r\n",
    "print(f'shape: {predictions.shape}');\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "logits prediction: \n",
      "tf.Tensor(\n",
      "[1.         0.99999994 0.99999994 1.         1.         1.0000001\n",
      " 0.99999994 1.0000001  1.         1.         1.         0.99999994\n",
      " 1.         1.0000002  1.0000001  0.9999999  1.0000001  1.0000001\n",
      " 1.         0.99999994 0.99999994 1.         1.         0.99999994\n",
      " 1.0000001  0.9999999  1.         0.99999994 0.99999994 1.\n",
      " 1.         0.9999999  0.9999998  1.0000002  0.99999994 1.0000001\n",
      " 1.         1.         1.         1.         0.9999999  0.99999994\n",
      " 1.0000001  1.0000001  1.         1.         0.99999994 0.99999994\n",
      " 1.         1.         1.0000001  0.9999999  1.         1.\n",
      " 0.99999994 1.         1.         1.         0.9999999  0.99999994\n",
      " 0.9999999  1.         1.0000001  1.         1.         1.\n",
      " 1.         1.0000001  1.         0.99999976 1.         0.99999994\n",
      " 1.         1.         0.99999994 0.9999999  1.0000002  1.\n",
      " 0.99999994 0.9999999  1.         0.9999999  1.         0.9999999\n",
      " 1.0000001  0.9999999  1.         0.99999994 1.0000001  1.0000001\n",
      " 1.0000001  0.9999999  1.0000001  1.         1.         1.\n",
      " 1.         0.99999994 0.99999994 1.         0.99999994 0.99999994\n",
      " 1.         0.9999999  1.         1.         0.99999994 1.0000001\n",
      " 0.99999994 0.9999998  1.         1.         0.9999999  0.99999994\n",
      " 0.99999994 0.9999999  1.         0.9999999  0.9999999  1.\n",
      " 1.0000001  0.9999999  0.9999999  0.99999994 0.9999999  0.9999999\n",
      " 0.99999994 1.0000001  1.0000001  0.99999994 1.0000001  1.\n",
      " 1.         0.9999999  1.         1.         0.9999998  0.99999994\n",
      " 1.0000001  1.         1.         1.         1.         1.\n",
      " 1.0000001  1.0000002  1.         1.0000001  1.         1.0000001\n",
      " 0.99999994 1.         1.0000001  1.         0.99999994 1.\n",
      " 0.9999999  1.         1.         0.9999997  0.99999994 1.\n",
      " 1.         0.99999994 1.0000001  1.         0.9999998  1.\n",
      " 1.         1.0000001  1.0000002  1.         1.         1.\n",
      " 0.9999999  1.0000001  1.0000001  1.0000001  1.         1.0000001\n",
      " 0.99999994 0.9999999  0.9999998  1.         1.         0.99999994\n",
      " 0.9999999  0.99999994 1.         0.9999998  0.99999994 0.99999994\n",
      " 1.0000001  1.         0.99999994 0.9999999  1.0000001  1.0000001\n",
      " 0.9999998  1.         1.         1.0000001  0.9999999  1.0000001\n",
      " 0.99999994 1.         1.         0.99999994 0.99999994 1.0000001\n",
      " 1.0000001  1.0000001  0.9999999  1.0000001  0.9999999  0.99999994\n",
      " 1.         1.         0.99999994 1.         1.         0.99999994\n",
      " 0.99999994 1.0000001  1.0000001  1.         0.99999994 1.\n",
      " 1.         1.0000001  0.99999976 1.         1.         1.\n",
      " 1.         1.0000002  0.9999999  0.99999994 1.0000001  0.99999994\n",
      " 0.9999999  0.9999999  0.99999994 1.0000001  1.         0.99999994\n",
      " 0.9999998  0.99999994 1.         1.         0.9999999  1.0000001\n",
      " 1.         1.         1.0000001  1.0000001  0.99999994 1.\n",
      " 1.         1.0000001  1.         1.         1.         1.0000001\n",
      " 1.0000001  1.         0.99999994 1.0000001  1.         1.\n",
      " 1.         0.99999994 1.0000001  1.0000001  1.         1.0000001\n",
      " 1.0000001  1.         1.         1.0000001  1.         0.9999999\n",
      " 1.0000001  1.         1.0000001  1.         1.         0.9999999\n",
      " 0.99999994 0.99999994 0.99999994 0.99999976 0.9999999  0.99999994\n",
      " 1.         1.         1.         0.99999994 0.99999994 1.0000001\n",
      " 1.         1.         0.9999999  1.         0.99999994 0.99999994\n",
      " 1.         0.99999994 1.0000001  1.         0.9999999  0.9999999\n",
      " 1.0000001  1.         1.0000001  0.9999999  1.0000001  1.\n",
      " 0.99999994 1.         1.0000001  0.9999999  0.9999999  1.0000002\n",
      " 0.99999994 1.         1.0000001  1.         1.         1.\n",
      " 0.99999994 0.9999999  0.9999998  0.99999994 0.99999994 0.9999999\n",
      " 1.0000001  0.99999994 1.0000001  1.0000001  1.         0.99999994\n",
      " 1.0000001  1.         0.99999994 0.99999994 1.0000001  0.9999999\n",
      " 0.99999994 1.         1.         0.99999976 1.         0.99999994\n",
      " 0.99999994 0.9999999  0.9999999  0.9999999  1.0000001  1.\n",
      " 0.9999999  1.         0.9999999  0.9999998  1.0000001  0.99999994\n",
      " 1.         1.0000001  1.         0.99999994 0.9999999  0.9999999\n",
      " 1.         1.0000001  1.         1.         0.9999999  0.99999994\n",
      " 1.         1.0000001  0.99999994 0.99999994 1.         1.\n",
      " 1.         1.0000001  1.         0.99999994 0.9999999  1.\n",
      " 0.9999998  0.99999994 1.         0.99999994 0.99999994 1.0000001\n",
      " 1.         1.0000001  1.         0.99999994 0.99999994 1.\n",
      " 1.         1.         1.         1.0000001  1.0000001  1.\n",
      " 1.         0.9999999  1.         1.         1.         1.\n",
      " 1.         0.9999999  0.99999994 1.         1.         0.99999994\n",
      " 0.9999999  1.0000001  1.0000001  0.99999994 1.         1.0000001\n",
      " 1.         1.0000001  1.0000001  1.         0.9999998  0.9999998\n",
      " 1.0000001  0.99999994 1.         1.0000001  0.99999976 1.\n",
      " 0.99999994 0.99999994 1.0000001  1.0000001  1.         0.99999994\n",
      " 1.0000001  0.99999994 1.0000001  1.0000001  1.0000001  1.\n",
      " 0.9999999  1.         0.99999994 1.         1.0000001  1.0000001\n",
      " 1.         1.0000001  0.99999994 1.0000002  1.0000001  0.9999999\n",
      " 0.9999999  1.         0.99999994 1.         0.9999999  1.\n",
      " 0.99999994 0.9999999  1.         0.99999994 1.         1.\n",
      " 0.99999994 1.0000001  1.         0.99999994 1.0000001  1.\n",
      " 0.99999994 0.99999994 1.         1.0000001  0.99999994 0.9999998\n",
      " 0.99999994 1.         1.0000001  1.         1.0000001  0.99999994\n",
      " 1.         1.         1.         1.0000001  1.         1.\n",
      " 0.9999998  1.        ], shape=(500,), dtype=float32)\n",
      "shape: (151, 500)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# get the loss function as a MeanSquaredError loss from tf.keras.losses. \r\n",
    "loss_fn = tf.keras.losses.MeanSquaredError();\r\n",
    "\r\n",
    "print(\"loss:\");\r\n",
    "print(loss_fn(y_train[0],predictions[0]).numpy());"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:\n",
      "685337100.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5);\r\n",
    "\r\n",
    "model.compile(loss=loss_fn,optimizer=opt,metrics=['accuracy']);\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "model.fit(x_train,y_train,epochs=15,validation_data=(x_test,y_test), batch_size=10);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/60\n",
      "16/16 [==============================] - 57s 3s/step - loss: 229957360.0000 - accuracy: 0.0000e+00 - val_loss: 45618112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 54s 3s/step - loss: 229878096.0000 - accuracy: 0.0000e+00 - val_loss: 45508740.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 229395536.0000 - accuracy: 0.0000e+00 - val_loss: 45024272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 227350576.0000 - accuracy: 0.0000e+00 - val_loss: 43225588.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 219366928.0000 - accuracy: 0.0000e+00 - val_loss: 36841592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 54s 3s/step - loss: 186577328.0000 - accuracy: 0.0000e+00 - val_loss: 24934528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 104162680.0000 - accuracy: 0.0000e+00 - val_loss: 54147140.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 36651976.0000 - accuracy: 0.0000e+00 - val_loss: 65518864.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 24533066.0000 - accuracy: 0.0000e+00 - val_loss: 59094456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22963390.0000 - accuracy: 0.0000e+00 - val_loss: 64320852.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22480044.0000 - accuracy: 0.0000e+00 - val_loss: 64250332.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 54s 3s/step - loss: 22555230.0000 - accuracy: 0.0000e+00 - val_loss: 62230996.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 54s 3s/step - loss: 22557038.0000 - accuracy: 0.0000e+00 - val_loss: 53986920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 23577986.0000 - accuracy: 0.0000e+00 - val_loss: 69864744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22711562.0000 - accuracy: 0.0000e+00 - val_loss: 55286720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22846102.0000 - accuracy: 0.0000e+00 - val_loss: 61221920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22456172.0000 - accuracy: 0.0000e+00 - val_loss: 60856756.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22288456.0000 - accuracy: 0.0000e+00 - val_loss: 55980040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22423494.0000 - accuracy: 0.0000e+00 - val_loss: 53487196.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 23054880.0000 - accuracy: 0.0000e+00 - val_loss: 65503844.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22566756.0000 - accuracy: 0.0000e+00 - val_loss: 63374900.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 23324244.0000 - accuracy: 0.0000e+00 - val_loss: 58022912.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22441416.0000 - accuracy: 0.0000e+00 - val_loss: 59681068.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 54s 3s/step - loss: 22334562.0000 - accuracy: 0.0000e+00 - val_loss: 57685568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 54s 3s/step - loss: 22540836.0000 - accuracy: 0.0000e+00 - val_loss: 60766256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22517310.0000 - accuracy: 0.0000e+00 - val_loss: 58084184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22714322.0000 - accuracy: 0.0000e+00 - val_loss: 56324956.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22646164.0000 - accuracy: 0.0000e+00 - val_loss: 52734072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 54s 3s/step - loss: 23476910.0000 - accuracy: 0.0000e+00 - val_loss: 67726496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22115276.0000 - accuracy: 0.0000e+00 - val_loss: 53675968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 23367338.0000 - accuracy: 0.0000e+00 - val_loss: 61658052.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22490884.0000 - accuracy: 0.0000e+00 - val_loss: 57502400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 23687002.0000 - accuracy: 0.0000e+00 - val_loss: 61381564.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22411136.0000 - accuracy: 0.0000e+00 - val_loss: 62211304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22695496.0000 - accuracy: 0.0000e+00 - val_loss: 62058856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22146676.0000 - accuracy: 0.0000e+00 - val_loss: 56345412.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22486804.0000 - accuracy: 0.0000e+00 - val_loss: 65117124.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22623774.0000 - accuracy: 0.0000e+00 - val_loss: 50338248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 23636332.0000 - accuracy: 0.0000e+00 - val_loss: 58306180.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22180602.0000 - accuracy: 0.0000e+00 - val_loss: 62067448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 54s 3s/step - loss: 22257688.0000 - accuracy: 0.0000e+00 - val_loss: 52547848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22648972.0000 - accuracy: 0.0000e+00 - val_loss: 66256956.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22159062.0000 - accuracy: 0.0000e+00 - val_loss: 58157424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22230548.0000 - accuracy: 0.0000e+00 - val_loss: 58061004.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22326150.0000 - accuracy: 0.0000e+00 - val_loss: 53376296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22650484.0000 - accuracy: 0.0000e+00 - val_loss: 61700312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22166498.0000 - accuracy: 0.0000e+00 - val_loss: 56524828.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22620182.0000 - accuracy: 0.0000e+00 - val_loss: 56108180.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22664480.0000 - accuracy: 0.0000e+00 - val_loss: 55695748.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22482840.0000 - accuracy: 0.0000e+00 - val_loss: 57164148.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22562572.0000 - accuracy: 0.0000e+00 - val_loss: 54520332.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 23675990.0000 - accuracy: 0.0000e+00 - val_loss: 57909568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 53s 3s/step - loss: 22485708.0000 - accuracy: 0.0000e+00 - val_loss: 66784756.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 49s 3s/step - loss: 24157396.0000 - accuracy: 0.0000e+00 - val_loss: 52455188.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 49s 3s/step - loss: 22419972.0000 - accuracy: 0.0000e+00 - val_loss: 64412328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 49s 3s/step - loss: 22335974.0000 - accuracy: 0.0000e+00 - val_loss: 60383740.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 49s 3s/step - loss: 23700396.0000 - accuracy: 0.0000e+00 - val_loss: 65084444.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 50s 3s/step - loss: 22835540.0000 - accuracy: 0.0000e+00 - val_loss: 59100160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 50s 3s/step - loss: 24140186.0000 - accuracy: 0.0000e+00 - val_loss: 57868120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 51s 3s/step - loss: 22350454.0000 - accuracy: 0.0000e+00 - val_loss: 67822808.0000 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "\r\n",
    "print(model.summary());"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 500)               1004000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               250500    \n",
      "=================================================================\n",
      "Total params: 1,505,000\n",
      "Trainable params: 1,505,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "predictions = model(x_train);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "graphnum = 25;\r\n",
    "\r\n",
    "first_graph = predictions[graphnum];\r\n",
    "print(predictions.shape);\r\n",
    "\r\n",
    "x = np.linspace(0,500,500);\r\n",
    "print(x.shape)\r\n",
    "\r\n",
    "pyplot.plot(first_graph);\r\n",
    "pyplot.plot(y_set[graphnum])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(151, 500)\n",
      "(500,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2070e525eb0>]"
      ]
     },
     "metadata": {},
     "execution_count": 35
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 388.0125 248.518125\" width=\"388.0125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-18T22:40:13.811419</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 388.0125 248.518125 \r\nL 388.0125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 46.0125 224.64 \r\nL 380.8125 224.64 \r\nL 380.8125 7.2 \r\nL 46.0125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mb26208d3cd\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"61.230682\" xlink:href=\"#mb26208d3cd\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(58.049432 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"122.225399\" xlink:href=\"#mb26208d3cd\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(112.681649 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"183.220115\" xlink:href=\"#mb26208d3cd\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 200 -->\r\n      <g transform=\"translate(173.676365 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"244.214832\" xlink:href=\"#mb26208d3cd\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 300 -->\r\n      <g transform=\"translate(234.671082 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2597 2516 \r\nQ 3050 2419 3304 2112 \r\nQ 3559 1806 3559 1356 \r\nQ 3559 666 3084 287 \r\nQ 2609 -91 1734 -91 \r\nQ 1441 -91 1130 -33 \r\nQ 819 25 488 141 \r\nL 488 750 \r\nQ 750 597 1062 519 \r\nQ 1375 441 1716 441 \r\nQ 2309 441 2620 675 \r\nQ 2931 909 2931 1356 \r\nQ 2931 1769 2642 2001 \r\nQ 2353 2234 1838 2234 \r\nL 1294 2234 \r\nL 1294 2753 \r\nL 1863 2753 \r\nQ 2328 2753 2575 2939 \r\nQ 2822 3125 2822 3475 \r\nQ 2822 3834 2567 4026 \r\nQ 2313 4219 1838 4219 \r\nQ 1578 4219 1281 4162 \r\nQ 984 4106 628 3988 \r\nL 628 4550 \r\nQ 988 4650 1302 4700 \r\nQ 1616 4750 1894 4750 \r\nQ 2613 4750 3031 4423 \r\nQ 3450 4097 3450 3541 \r\nQ 3450 3153 3228 2886 \r\nQ 3006 2619 2597 2516 \r\nz\r\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-33\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"305.209549\" xlink:href=\"#mb26208d3cd\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 400 -->\r\n      <g transform=\"translate(295.665799 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2419 4116 \r\nL 825 1625 \r\nL 2419 1625 \r\nL 2419 4116 \r\nz\r\nM 2253 4666 \r\nL 3047 4666 \r\nL 3047 1625 \r\nL 3713 1625 \r\nL 3713 1100 \r\nL 3047 1100 \r\nL 3047 0 \r\nL 2419 0 \r\nL 2419 1100 \r\nL 313 1100 \r\nL 313 1709 \r\nL 2253 4666 \r\nz\r\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-34\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"366.204265\" xlink:href=\"#mb26208d3cd\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 500 -->\r\n      <g transform=\"translate(356.660515 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 691 4666 \r\nL 3169 4666 \r\nL 3169 4134 \r\nL 1269 4134 \r\nL 1269 2991 \r\nQ 1406 3038 1543 3061 \r\nQ 1681 3084 1819 3084 \r\nQ 2600 3084 3056 2656 \r\nQ 3513 2228 3513 1497 \r\nQ 3513 744 3044 326 \r\nQ 2575 -91 1722 -91 \r\nQ 1428 -91 1123 -41 \r\nQ 819 9 494 109 \r\nL 494 744 \r\nQ 775 591 1075 516 \r\nQ 1375 441 1709 441 \r\nQ 2250 441 2565 725 \r\nQ 2881 1009 2881 1497 \r\nQ 2881 1984 2565 2268 \r\nQ 2250 2553 1709 2553 \r\nQ 1456 2553 1204 2497 \r\nQ 953 2441 691 2322 \r\nL 691 4666 \r\nz\r\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m0f737fe6ef\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m0f737fe6ef\" y=\"207.887026\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 15000 -->\r\n      <g transform=\"translate(7.2 211.686245)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m0f737fe6ef\" y=\"166.865294\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 16000 -->\r\n      <g transform=\"translate(7.2 170.664512)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2113 2584 \r\nQ 1688 2584 1439 2293 \r\nQ 1191 2003 1191 1497 \r\nQ 1191 994 1439 701 \r\nQ 1688 409 2113 409 \r\nQ 2538 409 2786 701 \r\nQ 3034 994 3034 1497 \r\nQ 3034 2003 2786 2293 \r\nQ 2538 2584 2113 2584 \r\nz\r\nM 3366 4563 \r\nL 3366 3988 \r\nQ 3128 4100 2886 4159 \r\nQ 2644 4219 2406 4219 \r\nQ 1781 4219 1451 3797 \r\nQ 1122 3375 1075 2522 \r\nQ 1259 2794 1537 2939 \r\nQ 1816 3084 2150 3084 \r\nQ 2853 3084 3261 2657 \r\nQ 3669 2231 3669 1497 \r\nQ 3669 778 3244 343 \r\nQ 2819 -91 2113 -91 \r\nQ 1303 -91 875 529 \r\nQ 447 1150 447 2328 \r\nQ 447 3434 972 4092 \r\nQ 1497 4750 2381 4750 \r\nQ 2619 4750 2861 4703 \r\nQ 3103 4656 3366 4563 \r\nz\r\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-36\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m0f737fe6ef\" y=\"125.843561\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 17000 -->\r\n      <g transform=\"translate(7.2 129.64278)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 525 4666 \r\nL 3525 4666 \r\nL 3525 4397 \r\nL 1831 0 \r\nL 1172 0 \r\nL 2766 4134 \r\nL 525 4134 \r\nL 525 4666 \r\nz\r\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-37\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m0f737fe6ef\" y=\"84.821828\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 18000 -->\r\n      <g transform=\"translate(7.2 88.621047)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2034 2216 \r\nQ 1584 2216 1326 1975 \r\nQ 1069 1734 1069 1313 \r\nQ 1069 891 1326 650 \r\nQ 1584 409 2034 409 \r\nQ 2484 409 2743 651 \r\nQ 3003 894 3003 1313 \r\nQ 3003 1734 2745 1975 \r\nQ 2488 2216 2034 2216 \r\nz\r\nM 1403 2484 \r\nQ 997 2584 770 2862 \r\nQ 544 3141 544 3541 \r\nQ 544 4100 942 4425 \r\nQ 1341 4750 2034 4750 \r\nQ 2731 4750 3128 4425 \r\nQ 3525 4100 3525 3541 \r\nQ 3525 3141 3298 2862 \r\nQ 3072 2584 2669 2484 \r\nQ 3125 2378 3379 2068 \r\nQ 3634 1759 3634 1313 \r\nQ 3634 634 3220 271 \r\nQ 2806 -91 2034 -91 \r\nQ 1263 -91 848 271 \r\nQ 434 634 434 1313 \r\nQ 434 1759 690 2068 \r\nQ 947 2378 1403 2484 \r\nz\r\nM 1172 3481 \r\nQ 1172 3119 1398 2916 \r\nQ 1625 2713 2034 2713 \r\nQ 2441 2713 2670 2916 \r\nQ 2900 3119 2900 3481 \r\nQ 2900 3844 2670 4047 \r\nQ 2441 4250 2034 4250 \r\nQ 1625 4250 1398 4047 \r\nQ 1172 3844 1172 3481 \r\nz\r\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-38\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m0f737fe6ef\" y=\"43.800096\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 19000 -->\r\n      <g transform=\"translate(7.2 47.599314)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 703 97 \r\nL 703 672 \r\nQ 941 559 1184 500 \r\nQ 1428 441 1663 441 \r\nQ 2288 441 2617 861 \r\nQ 2947 1281 2994 2138 \r\nQ 2813 1869 2534 1725 \r\nQ 2256 1581 1919 1581 \r\nQ 1219 1581 811 2004 \r\nQ 403 2428 403 3163 \r\nQ 403 3881 828 4315 \r\nQ 1253 4750 1959 4750 \r\nQ 2769 4750 3195 4129 \r\nQ 3622 3509 3622 2328 \r\nQ 3622 1225 3098 567 \r\nQ 2575 -91 1691 -91 \r\nQ 1453 -91 1209 -44 \r\nQ 966 3 703 97 \r\nz\r\nM 1959 2075 \r\nQ 2384 2075 2632 2365 \r\nQ 2881 2656 2881 3163 \r\nQ 2881 3666 2632 3958 \r\nQ 2384 4250 1959 4250 \r\nQ 1534 4250 1286 3958 \r\nQ 1038 3666 1038 3163 \r\nQ 1038 2656 1286 2365 \r\nQ 1534 2075 1959 2075 \r\nz\r\n\" id=\"DejaVuSans-39\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-39\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_12\">\r\n    <path clip-path=\"url(#p5c51595dba)\" d=\"M 61.230682 213.680184 \r\nL 61.840629 213.985884 \r\nL 62.450576 214.140397 \r\nL 63.060523 213.285951 \r\nL 63.67047 213.93008 \r\nL 64.280418 213.540654 \r\nL 64.890365 212.902494 \r\nL 65.500312 213.287673 \r\nL 66.110259 213.924271 \r\nL 66.720206 213.283627 \r\nL 67.330153 213.293482 \r\nL 67.940101 213.994016 \r\nL 69.159995 213.79063 \r\nL 69.769942 213.276056 \r\nL 70.379889 214.179896 \r\nL 70.989836 213.276056 \r\nL 71.599784 214.184543 \r\nL 72.209731 213.855728 \r\nL 72.819678 213.784221 \r\nL 73.429625 214.166516 \r\nL 74.039572 213.826084 \r\nL 74.649519 213.798162 \r\nL 75.259467 213.295846 \r\nL 75.869414 214.183942 \r\nL 76.479361 214.132865 \r\nL 77.089308 213.442987 \r\nL 77.699255 213.285951 \r\nL 78.309202 214.180457 \r\nL 79.529097 213.29232 \r\nL 80.139044 213.289436 \r\nL 80.748991 213.748206 \r\nL 81.358938 213.288835 \r\nL 81.968885 213.947506 \r\nL 82.578833 213.563328 \r\nL 83.18878 213.933005 \r\nL 83.798727 213.547064 \r\nL 84.408674 213.825483 \r\nL 85.018621 213.29232 \r\nL 85.628569 213.283026 \r\nL 86.238516 213.422036 \r\nL 86.848463 213.281865 \r\nL 87.45841 214.055589 \r\nL 88.068357 214.139235 \r\nL 88.678304 213.319081 \r\nL 89.288252 214.079385 \r\nL 89.898199 214.166516 \r\nL 90.508146 213.285951 \r\nL 91.118093 213.89695 \r\nL 91.72804 213.285951 \r\nL 92.337987 213.732503 \r\nL 92.947935 213.738912 \r\nL 93.557882 213.368515 \r\nL 94.167829 213.974828 \r\nL 94.777776 214.139836 \r\nL 95.99767 213.864421 \r\nL 96.607618 213.947506 \r\nL 97.217565 214.181619 \r\nL 97.827512 213.29176 \r\nL 98.437459 213.927757 \r\nL 100.267301 214.175249 \r\nL 102.097142 214.024783 \r\nL 102.707089 213.556358 \r\nL 103.317036 213.93008 \r\nL 103.926984 214.088118 \r\nL 104.536931 213.270808 \r\nL 105.146878 213.305701 \r\nL 106.366772 213.818512 \r\nL 106.976719 213.448195 \r\nL 107.586667 213.957962 \r\nL 108.196614 213.942859 \r\nL 108.806561 214.140998 \r\nL 109.416508 213.370278 \r\nL 110.026455 214.185104 \r\nL 110.636402 214.020737 \r\nL 111.24635 213.319682 \r\nL 111.856297 213.798162 \r\nL 113.076191 213.939975 \r\nL 113.686138 213.311549 \r\nL 114.296085 213.285951 \r\nL 114.906033 213.955639 \r\nL 115.51598 213.29176 \r\nL 116.125927 214.137512 \r\nL 116.735874 213.954477 \r\nL 117.345821 213.288274 \r\nL 118.565716 213.291159 \r\nL 119.175663 213.441825 \r\nL 119.78561 213.451119 \r\nL 120.395557 213.932404 \r\nL 121.005504 213.952754 \r\nL 121.615451 213.853405 \r\nL 122.225399 213.276617 \r\nL 123.445293 213.273132 \r\nL 124.05524 214.106145 \r\nL 124.665187 213.934166 \r\nL 125.275134 214.064883 \r\nL 125.885082 213.886495 \r\nL 126.495029 214.054427 \r\nL 127.104976 213.36503 \r\nL 127.714923 213.425521 \r\nL 128.32487 213.299892 \r\nL 128.934817 214.160146 \r\nL 129.544765 213.940536 \r\nL 130.154712 214.123571 \r\nL 130.764659 213.258029 \r\nL 131.374606 213.952754 \r\nL 131.984553 213.297568 \r\nL 132.5945 213.940536 \r\nL 133.204448 213.93649 \r\nL 133.814395 214.081148 \r\nL 134.424342 213.290598 \r\nL 135.034289 213.820275 \r\nL 135.644236 213.28535 \r\nL 136.254183 213.266161 \r\nL 136.864131 213.734225 \r\nL 137.474078 214.013766 \r\nL 138.084025 213.287113 \r\nL 138.693972 213.928918 \r\nL 139.303919 213.361545 \r\nL 140.523814 214.18222 \r\nL 141.133761 213.387704 \r\nL 141.743708 214.181058 \r\nL 142.353655 214.060797 \r\nL 142.963602 214.184543 \r\nL 143.573549 213.282466 \r\nL 144.183497 213.981798 \r\nL 144.793444 213.800485 \r\nL 146.013338 213.759824 \r\nL 146.623285 213.286512 \r\nL 147.233232 213.814466 \r\nL 147.84318 213.289436 \r\nL 148.453127 214.165354 \r\nL 149.063074 213.383658 \r\nL 150.282968 213.540654 \r\nL 150.892915 213.532522 \r\nL 151.502863 214.107868 \r\nL 152.11281 213.819113 \r\nL 152.722757 213.293482 \r\nL 153.942651 213.297007 \r\nL 154.552598 213.955639 \r\nL 155.162546 213.296407 \r\nL 155.772493 213.802809 \r\nL 156.992387 214.18222 \r\nL 157.602334 213.729018 \r\nL 158.212281 213.816189 \r\nL 158.822229 213.742398 \r\nL 159.432176 213.939374 \r\nL 160.042123 213.94346 \r\nL 160.65207 213.277779 \r\nL 161.262017 214.150852 \r\nL 161.871964 213.935889 \r\nL 162.481912 214.044532 \r\nL 164.311753 213.280142 \r\nL 164.9217 213.905683 \r\nL 165.531647 213.824922 \r\nL 166.141595 213.935328 \r\nL 166.751542 213.425521 \r\nL 167.361489 213.941137 \r\nL 167.971436 213.399922 \r\nL 168.581383 213.300493 \r\nL 169.19133 213.853966 \r\nL 169.801278 213.281865 \r\nL 170.411225 213.287673 \r\nL 171.021172 214.068368 \r\nL 171.631119 213.946946 \r\nL 172.241066 213.425521 \r\nL 172.851013 213.294684 \r\nL 174.070908 214.150852 \r\nL 174.680855 213.430769 \r\nL 175.290802 214.142159 \r\nL 175.900749 214.089881 \r\nL 176.510696 213.573223 \r\nL 177.120644 214.142159 \r\nL 177.730591 214.041047 \r\nL 178.340538 214.164793 \r\nL 178.950485 213.809218 \r\nL 179.560432 213.300493 \r\nL 180.170379 213.905123 \r\nL 180.780327 213.282466 \r\nL 181.390274 213.152149 \r\nL 182.000221 213.941698 \r\nL 182.610168 214.165955 \r\nL 183.220115 213.273732 \r\nL 183.830062 213.408095 \r\nL 184.44001 214.183381 \r\nL 185.659904 213.298169 \r\nL 186.269851 213.415626 \r\nL 186.879798 213.29232 \r\nL 187.489745 213.577269 \r\nL 188.099693 214.045694 \r\nL 188.70964 213.421435 \r\nL 189.319587 213.281865 \r\nL 189.929534 214.077662 \r\nL 190.539481 213.941698 \r\nL 191.149428 214.093366 \r\nL 191.759376 213.51101 \r\nL 192.369323 213.947506 \r\nL 192.97927 213.435977 \r\nL 193.589217 214.164793 \r\nL 194.199164 213.944021 \r\nL 194.809111 213.409817 \r\nL 195.419059 213.944021 \r\nL 196.029006 214.056751 \r\nL 196.638953 213.805132 \r\nL 197.2489 213.766794 \r\nL 197.858847 213.289997 \r\nL 198.468794 213.931843 \r\nL 199.078742 214.033516 \r\nL 199.688689 213.288835 \r\nL 200.298636 213.790029 \r\nL 200.908583 213.289436 \r\nL 201.51853 213.915578 \r\nL 202.128477 213.9568 \r\nL 202.738425 213.33887 \r\nL 204.568266 213.283627 \r\nL 205.178213 213.806294 \r\nL 205.78816 214.139836 \r\nL 207.008055 213.726694 \r\nL 208.227949 213.858052 \r\nL 208.837896 214.165955 \r\nL 209.447843 213.947506 \r\nL 210.057791 213.283026 \r\nL 210.667738 213.928918 \r\nL 211.277685 213.439462 \r\nL 211.887632 214.080547 \r\nL 212.497579 213.838863 \r\nL 213.107526 214.010842 \r\nL 213.717474 213.819674 \r\nL 214.327421 213.420874 \r\nL 214.937368 213.928358 \r\nL 215.547315 214.163632 \r\nL 216.157262 213.470869 \r\nL 216.767209 213.571461 \r\nL 217.377157 213.925433 \r\nL 217.987104 213.274293 \r\nL 218.597051 213.295245 \r\nL 219.206998 213.569137 \r\nL 219.816945 213.348765 \r\nL 220.426892 213.315595 \r\nL 221.03684 213.926595 \r\nL 221.646787 213.290598 \r\nL 222.256734 214.176972 \r\nL 222.866681 213.423197 \r\nL 223.476628 214.158424 \r\nL 224.086575 213.329576 \r\nL 224.696523 214.179896 \r\nL 225.30647 214.081148 \r\nL 225.916417 213.333062 \r\nL 226.526364 214.154939 \r\nL 227.136311 213.945183 \r\nL 227.746258 213.955639 \r\nL 228.356206 213.292921 \r\nL 228.966153 214.118323 \r\nL 229.5761 213.313272 \r\nL 230.795994 213.933565 \r\nL 231.405941 214.027707 \r\nL 232.015889 213.269085 \r\nL 232.625836 213.286512 \r\nL 233.235783 214.756364 \r\nL 234.455677 213.287113 \r\nL 235.065624 214.02306 \r\nL 237.505413 213.927757 \r\nL 238.11536 214.121809 \r\nL 238.725307 213.294684 \r\nL 239.335255 213.815628 \r\nL 240.555149 214.181619 \r\nL 241.165096 213.290598 \r\nL 242.38499 213.27197 \r\nL 242.994938 213.792954 \r\nL 243.604885 213.31852 \r\nL 244.214832 214.126456 \r\nL 244.824779 214.12938 \r\nL 245.434726 213.817951 \r\nL 246.044673 214.164192 \r\nL 246.654621 214.038724 \r\nL 247.264568 213.280142 \r\nL 247.874515 214.164793 \r\nL 248.484462 214.007957 \r\nL 249.094409 214.080547 \r\nL 250.924251 213.69705 \r\nL 251.534198 213.286512 \r\nL 252.144145 214.023621 \r\nL 252.754092 213.515056 \r\nL 253.364039 213.694726 \r\nL 253.973987 213.741236 \r\nL 254.583934 214.168839 \r\nL 255.193881 214.108469 \r\nL 255.803828 213.294684 \r\nL 256.413775 213.941698 \r\nL 257.023722 213.806895 \r\nL 257.63367 213.939374 \r\nL 258.243617 213.57787 \r\nL 258.853564 214.18278 \r\nL 260.073458 214.110191 \r\nL 260.683405 213.288835 \r\nL 261.9033 213.29176 \r\nL 262.513247 213.807456 \r\nL 263.733141 213.691802 \r\nL 264.343088 214.081148 \r\nL 264.953036 213.792353 \r\nL 265.562983 214.163031 \r\nL 266.17293 213.281304 \r\nL 266.782877 213.731341 \r\nL 267.392824 213.930681 \r\nL 268.002771 213.527875 \r\nL 268.612719 213.287113 \r\nL 269.222666 213.927757 \r\nL 269.832613 214.186266 \r\nL 270.44256 213.317919 \r\nL 271.052507 213.301654 \r\nL 271.662454 213.94983 \r\nL 272.272402 213.337108 \r\nL 272.882349 214.034678 \r\nL 274.102243 213.824321 \r\nL 274.71219 214.168279 \r\nL 275.322137 213.786544 \r\nL 275.932085 214.170602 \r\nL 276.542032 213.543579 \r\nL 277.151979 214.170001 \r\nL 277.761926 213.277218 \r\nL 278.371873 213.933565 \r\nL 278.98182 213.292921 \r\nL 279.591768 213.295846 \r\nL 280.201715 213.831292 \r\nL 281.421609 213.999825 \r\nL 282.031556 213.950992 \r\nL 282.641503 214.18919 \r\nL 283.861398 213.419712 \r\nL 284.471345 213.917301 \r\nL 285.081292 213.289436 \r\nL 285.691239 214.120647 \r\nL 286.301186 213.571461 \r\nL 286.911134 213.94983 \r\nL 287.521081 213.32493 \r\nL 288.131028 214.154338 \r\nL 288.740975 213.34528 \r\nL 289.350922 213.953315 \r\nL 289.960869 213.290598 \r\nL 290.570817 213.353412 \r\nL 291.180764 213.271409 \r\nL 291.790711 214.181058 \r\nL 292.400658 213.818512 \r\nL 294.2305 213.733665 \r\nL 294.840447 213.756339 \r\nL 295.450394 213.291159 \r\nL 296.060341 214.18278 \r\nL 296.670288 214.177573 \r\nL 297.280235 213.285951 \r\nL 297.890183 214.078223 \r\nL 299.720024 214.187427 \r\nL 300.939918 214.116601 \r\nL 301.549866 213.534244 \r\nL 302.159813 213.957401 \r\nL 302.76976 213.29873 \r\nL 303.379707 213.963811 \r\nL 303.989654 214.013766 \r\nL 304.599601 213.752853 \r\nL 305.209549 213.289436 \r\nL 305.819496 213.952153 \r\nL 306.429443 213.423197 \r\nL 307.03939 213.967296 \r\nL 307.649337 213.933565 \r\nL 308.259284 213.294684 \r\nL 308.869232 213.696449 \r\nL 310.089126 213.935328 \r\nL 310.699073 214.186266 \r\nL 311.30902 214.131103 \r\nL 311.918967 213.289997 \r\nL 312.528915 213.27894 \r\nL 313.138862 213.806895 \r\nL 313.748809 213.289436 \r\nL 314.358756 213.287673 \r\nL 314.968703 214.084633 \r\nL 315.57865 214.048018 \r\nL 316.188598 213.731902 \r\nL 316.798545 213.281865 \r\nL 317.408492 213.305701 \r\nL 318.018439 213.799924 \r\nL 318.628386 213.392391 \r\nL 319.848281 214.172926 \r\nL 320.458228 213.90336 \r\nL 321.068175 213.346442 \r\nL 321.678122 213.284188 \r\nL 322.288069 214.172926 \r\nL 322.898016 213.932404 \r\nL 323.507964 213.948107 \r\nL 324.727858 214.152014 \r\nL 325.337805 213.490659 \r\nL 325.947752 213.425521 \r\nL 326.557699 214.16247 \r\nL 327.777594 214.172926 \r\nL 328.387541 213.415065 \r\nL 328.997488 214.132865 \r\nL 329.607435 214.063721 \r\nL 330.217382 213.747045 \r\nL 330.82733 214.096851 \r\nL 331.437277 213.946345 \r\nL 332.047224 213.300493 \r\nL 333.267118 213.726694 \r\nL 333.877065 213.949269 \r\nL 334.487013 213.734225 \r\nL 335.09696 213.930681 \r\nL 335.706907 213.501115 \r\nL 336.316854 213.288835 \r\nL 336.926801 213.933005 \r\nL 337.536748 213.73715 \r\nL 338.756643 213.930681 \r\nL 339.36659 213.532522 \r\nL 339.976537 213.398761 \r\nL 340.586484 213.938813 \r\nL 341.196431 213.298169 \r\nL 341.806379 213.869068 \r\nL 342.416326 214.185705 \r\nL 343.63622 213.278379 \r\nL 344.246167 213.831892 \r\nL 344.856115 213.429006 \r\nL 345.466062 214.186867 \r\nL 346.076009 213.633113 \r\nL 346.685956 213.286512 \r\nL 347.295903 213.797 \r\nL 347.90585 213.287113 \r\nL 348.515798 213.289997 \r\nL 349.125745 213.941137 \r\nL 349.735692 214.147367 \r\nL 350.345639 214.008518 \r\nL 350.955586 213.344679 \r\nL 351.565533 213.319682 \r\nL 352.175481 214.188028 \r\nL 352.785428 214.150852 \r\nL 353.395375 213.492382 \r\nL 354.005322 213.279541 \r\nL 354.615269 214.04281 \r\nL 355.225216 213.804571 \r\nL 355.835164 213.736549 \r\nL 357.055058 213.98296 \r\nL 357.665005 213.846995 \r\nL 358.884899 214.157262 \r\nL 359.494847 213.278379 \r\nL 360.104794 213.284789 \r\nL 360.714741 214.172926 \r\nL 361.324688 213.913255 \r\nL 361.934635 214.170001 \r\nL 362.544582 213.288835 \r\nL 363.15453 213.754576 \r\nL 363.764477 213.282466 \r\nL 364.374424 213.934727 \r\nL 365.594318 213.9568 \r\nL 365.594318 213.9568 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p5c51595dba)\" d=\"M 61.230682 17.083636 \r\nL 365.594318 17.083636 \r\nL 365.594318 17.083636 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 46.0125 224.64 \r\nL 46.0125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 380.8125 224.64 \r\nL 380.8125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 46.0125 224.64 \r\nL 380.8125 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 46.0125 7.2 \r\nL 380.8125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p5c51595dba\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"46.0125\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "print(first_graph)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[14858.807  14851.341  14847.56   14868.375  14852.672  14862.18\n",
      " 14877.75   14868.36   14852.813  14868.445  14868.205  14851.128\n",
      " 14853.494  14856.086  14868.63   14846.611  14868.63   14846.483\n",
      " 14854.485  14856.242  14846.923  14855.193  14855.874  14868.147\n",
      " 14846.498  14847.701  14864.561  14868.389  14846.583  14856.157\n",
      " 14868.247  14868.318  14857.12   14868.304  14852.262  14861.627\n",
      " 14852.615  14862.023  14855.236  14868.233  14868.46   14865.071\n",
      " 14868.488  14849.642  14847.573  14867.581  14849.047  14846.923\n",
      " 14868.389  14853.4795 14868.389  14857.518  14857.347  14866.376\n",
      " 14851.596  14847.573  14852.162  14854.287  14852.233  14846.555\n",
      " 14868.247  14852.729  14850.406  14847.856  14846.725  14847.63\n",
      " 14850.42   14850.378  14861.797  14852.687  14848.862  14868.743\n",
      " 14867.907  14860.989  14855.406  14864.419  14852.007  14852.375\n",
      " 14847.531  14866.333  14846.455  14850.477  14867.566  14855.902\n",
      " 14853.238  14852.445  14867.765  14868.389  14852.077  14868.262\n",
      " 14847.616  14852.092  14868.347  14868.091  14868.262  14864.589\n",
      " 14864.349  14852.644  14852.134  14854.556  14868.63   14868.375\n",
      " 14868.687  14848.395  14852.602  14849.387  14853.763  14849.655\n",
      " 14866.461  14864.986  14868.049  14847.078  14852.432  14847.984\n",
      " 14869.041  14852.134  14868.091  14852.445  14852.53   14848.99\n",
      " 14868.262  14855.363  14868.403  14868.871  14857.461  14850.661\n",
      " 14868.347  14852.715  14866.546  14855.646  14846.555  14865.908\n",
      " 14846.555  14849.514  14846.483  14868.474  14851.426  14855.846\n",
      " 14855.831  14856.823  14868.389  14855.52   14868.304  14846.951\n",
      " 14865.993  14863.285  14862.193  14862.393  14848.353  14855.42\n",
      " 14868.205  14868.134  14868.119  14852.063  14868.134  14855.789\n",
      " 14852.063  14846.54   14857.603  14855.463  14857.248  14852.46\n",
      " 14852.36   14868.588  14847.29   14852.559  14849.882  14855.335\n",
      " 14860.833  14868.517  14853.267  14855.25   14852.559  14864.986\n",
      " 14852.417  14865.624  14868.049  14854.542  14868.488  14868.347\n",
      " 14849.315  14852.275  14864.986  14868.176  14856.682  14847.29\n",
      " 14864.858  14847.531  14848.791  14861.386  14847.517  14849.981\n",
      " 14846.951  14855.633  14868.034  14853.295  14868.474  14871.665\n",
      " 14852.403  14846.937  14868.673  14865.426  14846.498  14857.305\n",
      " 14868.077  14865.199  14868.233  14861.259  14849.854  14865.071\n",
      " 14868.474  14849.075  14852.403  14848.706  14862.902  14852.262\n",
      " 14864.731  14846.965  14852.347  14865.369  14852.332  14849.599\n",
      " 14855.746  14856.667  14868.29   14852.63   14850.151  14868.332\n",
      " 14856.114  14868.318  14853.04   14852.063  14867.127  14868.304\n",
      " 14867.779  14868.432  14855.704  14847.573  14851.751  14857.645\n",
      " 14856.029  14854.457  14846.937  14852.262  14868.46   14852.729\n",
      " 14864.632  14848.99   14854.91   14850.731  14855.378  14865.1\n",
      " 14852.729  14846.993  14863.881  14861.429  14852.8    14868.673\n",
      " 14868.147  14861.485  14866.857  14867.666  14852.771  14868.262\n",
      " 14846.668  14865.028  14847.12   14867.325  14846.597  14849.004\n",
      " 14867.227  14847.205  14852.318  14852.063  14868.205  14848.111\n",
      " 14867.723  14859.586  14852.615  14850.293  14868.8    14868.403\n",
      " 14832.544  14851.609  14868.347  14850.448  14851.652  14852.757\n",
      " 14852.162  14852.743  14847.984  14868.176  14855.463  14850.788\n",
      " 14846.54   14868.262  14868.147  14868.701  14856.029  14867.595\n",
      " 14847.913  14847.843  14855.42   14846.9795 14850.038  14868.53\n",
      " 14846.951  14850.788  14849.032  14852.517  14855.59   14858.382\n",
      " 14868.375  14850.42   14862.832  14858.424  14857.29   14846.866\n",
      " 14848.338  14868.19   14852.417  14855.689  14852.474  14861.272\n",
      " 14846.526  14846.895  14848.296  14868.318  14868.46   14868.247\n",
      " 14855.661  14856.101  14858.48   14849.019  14856.058  14847.021\n",
      " 14868.502  14857.531  14852.687  14862.506  14868.375  14852.743\n",
      " 14846.441  14867.623  14868.0205 14852.205  14867.155  14850.137\n",
      " 14851.979  14855.25   14846.88   14856.186  14846.823  14862.095\n",
      " 14846.852  14868.602  14852.602  14868.205  14868.147  14855.08\n",
      " 14852.771  14850.973  14852.177  14846.356  14854.315  14865.128\n",
      " 14852.983  14868.318  14848.041  14861.414  14852.219  14867.438\n",
      " 14847.233  14866.929  14852.105  14868.275  14866.73   14868.758\n",
      " 14846.568  14855.406  14856.738  14855.944  14857.475  14856.937\n",
      " 14868.262  14846.54   14846.653  14868.389  14849.061  14847.361\n",
      " 14846.823  14846.413  14847.333  14848.168  14862.336  14852.035\n",
      " 14868.0625 14851.864  14850.646  14857.007  14868.304  14852.148\n",
      " 14865.043  14851.794  14852.615  14868.176  14858.354  14855.902\n",
      " 14852.559  14846.427  14847.786  14868.29   14868.56   14855.689\n",
      " 14868.304  14868.36   14848.891  14849.812  14857.518  14868.502\n",
      " 14867.907  14855.859  14865.78   14856.129  14846.767  14853.338\n",
      " 14866.929  14868.445  14846.767  14852.63   14852.233  14848.734\n",
      " 14847.276  14863.398  14864.972  14847.035  14847.064  14846.767\n",
      " 14865.241  14847.758  14849.429  14857.163  14848.621  14852.304\n",
      " 14868.034  14863.866  14857.645  14852.219  14857.461  14852.672\n",
      " 14863.144  14868.318  14852.615  14857.39   14855.208  14852.658\n",
      " 14862.378  14865.652  14852.488  14868.077  14854.174  14846.483\n",
      " 14858.297  14868.56   14855.08   14864.901  14846.441  14859.94\n",
      " 14868.389  14855.931  14868.36   14868.275  14852.445  14847.39\n",
      " 14850.788  14866.957  14867.566  14846.398  14847.305  14863.356\n",
      " 14868.545  14849.91   14855.746  14857.39   14853.508  14851.411\n",
      " 14854.712  14852.162  14847.135  14868.56   14868.417  14846.767\n",
      " 14853.068  14846.838  14868.318  14856.979  14868.46   14852.545\n",
      " 14852.474  14852.035 ], shape=(500,), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}